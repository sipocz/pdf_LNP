{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change log\n",
    "# 20220213 linux install Mongodb\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip \n",
    "#!pip install pymongo[srv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz as pymupdf\n",
    "import pandas as pd \n",
    "import platform\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "_mongo_conn_=f\"mongodb+srv://{getenv('mongo_usr')}:{getenv('mongo_pwd')}@cluster0.fuant.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\"\n",
    "_MONGODB_=\"PDF_DB\"\n",
    "_MONGOCOLL_=\"ABB_pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mongo_client = pymongo.MongoClient(_mongo_conn_)\n",
    "mongo_db = mongo_client.test\n",
    "\n",
    "\n",
    "mongo_db = mongo_client[_MONGODB_]\n",
    "mongo_col=mongo_db[_MONGOCOLL_]\n",
    "\n",
    "\n",
    "# mongo_col.drop()   # Csak ha ki kell törölni az adatbázist !!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(Database(MongoClient(host=['cluster0-shard-00-01.fuant.mongodb.net:27017', 'cluster0-shard-00-02.fuant.mongodb.net:27017', 'cluster0-shard-00-00.fuant.mongodb.net:27017'], document_class=dict, tz_aware=False, connect=True, retrywrites=True, w='majority', authsource='admin', replicaset='atlas-11exxn-shard-0', tls=True), 'PDF_DB'), 'ABB_pdf')\n"
     ]
    }
   ],
   "source": [
    "print(mongo_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****   DROP MONGO DATABASE   ****\n",
    "#mongo_col.drop() # test database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os_str=platform.platform()\n",
    "if \"Windows\" in os_str:\n",
    "    _OS_=\"windows\"\n",
    "else:\n",
    "    _OS_=\"linux\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _OS_== \"linux\":\n",
    "    _testpdf_=\"/Users/sipocz/Downloads/abb/7PAA000908_A_en_SECURITY - OPC Server for AC 800M - Remote Code Execution Vulnerability.pdf\"  #csak a png kimenet miatt kell!\n",
    "    _pdflist_=\"/ABB/pdf_list_20220226.csv\"\n",
    "    _corpus_=\"/corpus/\"\n",
    "    _corpus_name_=\"ABB_sentences_20220315_2330000.txt\"\n",
    "else:\n",
    " \n",
    "    _testpdf_=\"C:/Users/sipocz/Downloads/abb/7PAA000908_A_en_SECURITY - OPC Server for AC 800M - Remote Code Execution Vulnerability.pdf\"  #csak a png kimenet miatt kell!\n",
    "    _pdflist_=\"D:/ArXiv_nlp/ArXiv_pdf_list_20220318.csv\"\n",
    "    _corpus_=\"D:/arXiv_nlp/corpus/\"\n",
    "    _corpus_name_=\"arXiv_sentences_20220318_133000.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=open(_pdflist_)\n",
    "doclist=[]\n",
    "for f in df:\n",
    "    doclist.append(f.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pymupdf.open(_testpdf_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=f.load_page(5)\n",
    "page_pix=page.get_pixmap()\n",
    "page_pix\n",
    "page_pix.save(\"p0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "img=Image.open(\"p0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Drawer = ImageDraw.Draw(img)\n",
    "Drawer.rectangle((64, 29, 211, 59), outline=\"red\",width=1)\n",
    "img.save(\"p1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fname_separator(fname):\n",
    "    '''\n",
    "    *** TASK: PNG OUTPUT\n",
    "    input: fname egy fájl neve\n",
    "    return: megadott fname file könyvtára, fole neve, és kiterjesztése  \n",
    "    '''\n",
    "    import os\n",
    "    temp = os.path.splitext(fname)\n",
    "    out = (os.path.dirname(fname),os.path.basename(temp[0]), temp[1])\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 'asdfr', '.png')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname_separator(\"asdfr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(fname,page=0):\n",
    "    '''\n",
    "    \n",
    "    *** TASK: CORPUS GENERATOR\n",
    "\n",
    "    - adott fname nevű pdf file teljes txt állományát exportálja pa page változó 0.\n",
    "    - megadott page esetén 0-pagi-ig !!!\n",
    "    - \n",
    "    \n",
    "        load_page.get_text(\"blocks\") feldolgozása\n",
    "    \n",
    "    '''\n",
    "    import os\n",
    "    meta_out=[]\n",
    "    \n",
    "\n",
    "    f = pymupdf.open(fname)\n",
    "    \n",
    "    txt = f.load_page(page).get_text(\"blocks\")\n",
    "    if page==0:\n",
    "        allpage=f.page_count\n",
    "    else:\n",
    "        allpage=page\n",
    "    temp=os.path.splitext(fname)\n",
    "\n",
    "    filename_mini=os.path.basename(temp[0])\n",
    "    #print('filename:',   filename_mini)                                #DEBUG\n",
    "    #print('Page Number:',   f.page_count)                              #DEBUG\n",
    "    #print('Creation Date:', f.metadata['creationDate'])                #DEBUG\n",
    "    #print('Modified Date:', f.metadata['modDate'])                     #DEBUG\n",
    "    #print('\\nTable of Content:\\n', [toc for toc in f.get_toc()])       #DEBUG\n",
    "    \n",
    "    txt_out=[]\n",
    "    for i in range(allpage):  # \n",
    "        #print(f\"ActualPage: {i}\")\n",
    "        txt = f.load_page(i).get_text(\"blocks\")\n",
    "        for line_i in txt:\n",
    "            meta_rec={}\n",
    "            meta_rec={\"_id\":0,\"index\":0,\"fname\":filename_mini, \"page\":i,\"pos0\":int(line_i[0]),\"pos1\":int(line_i[1]),\"pos2\":int(line_i[2]),\"pos3\":int(line_i[3])}\n",
    "            txt_i=line_i[4].replace(\"\\n\",\" \")\n",
    "            if len(set(txt_i))>3: # \n",
    "                txt_out.append(txt_i)\n",
    "                meta_out.append(meta_rec)\n",
    "            else:\n",
    "                \n",
    "                #print(txt_i) #DEBUG\n",
    "                pass \n",
    "            #print(txt_i)\n",
    "    return(txt_out,meta_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(file_list):\n",
    "    '''\n",
    "    *** TASK: CORPUS GENERATOR\n",
    "    \n",
    "    desc: corpus adatbázis létrehozása\n",
    "    out: corpus lista, metaadat lista\n",
    "\n",
    "\n",
    "    '''\n",
    "    i=0\n",
    "    text_out=[]\n",
    "    meta_out=[]\n",
    "    for file_name in file_list:\n",
    "        path_file=file_name\n",
    "        i+=1\n",
    "        if i % 100 ==0 :\n",
    "            print(f\"{i:3} --> {path_file}\")\n",
    "        text,meta=extract_text(path_file)\n",
    "        text_out=text_out+text # fájlonként összegezzük\n",
    "        meta_out=meta_out+meta # fájlonként összegezzük\n",
    "    return(text_out,meta_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (10438 0 R)\n",
      "mupdf: could not parse color space (20499 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 --> D:/arXiv//2202.02518.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (740 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 --> D:/arXiv//2202.02709.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 --> D:/arXiv//2202.02915.pdf\n",
      "400 --> D:/arXiv//2202.03129.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (217 0 R)\n",
      "mupdf: could not parse color space (602 0 R)\n",
      "mupdf: could not parse color space (647 0 R)\n",
      "mupdf: could not parse color space (851 0 R)\n",
      "mupdf: could not parse color space (1145 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 --> D:/arXiv//2202.03335.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '216mm'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '279mm'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 --> D:/arXiv//2202.03578.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n",
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 --> D:/arXiv//2202.03770.pdf\n",
      "800 --> D:/arXiv//2202.03986.pdf\n",
      "900 --> D:/arXiv//2202.04235.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n",
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 --> D:/arXiv//2202.04500.pdf\n",
      "1100 --> D:/arXiv//2202.04748.pdf\n",
      "1200 --> D:/arXiv//2202.04982.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: No default Layer config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 --> D:/arXiv//2202.05223.pdf\n",
      "1400 --> D:/arXiv//2202.05460.pdf\n",
      "1500 --> D:/arXiv//2202.05700.pdf\n",
      "1600 --> D:/arXiv//2202.05929.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (211 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 --> D:/arXiv//2202.06143.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: expected object number\n",
      "mupdf: expected object number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 --> D:/arXiv//2202.06345.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (642 0 R)\n",
      "mupdf: could not parse color space (690 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 --> D:/arXiv//2202.06544.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (647 0 R)\n",
      "mupdf: could not parse color space (749 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 --> D:/arXiv//2202.06776.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (140 0 R)\n",
      "mupdf: could not parse color space (238 0 R)\n",
      "mupdf: could not parse color space (390 0 R)\n",
      "mupdf: could not parse color space (313 0 R)\n",
      "mupdf: could not parse color space (405 0 R)\n",
      "mupdf: could not parse color space (584 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 --> D:/arXiv//2202.07052.pdf\n",
      "2200 --> D:/arXiv//2202.07262.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '597.50787pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '845.04684pt'\n",
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '597.50787pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '845.04684pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 --> D:/arXiv//2202.07496.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (421 0 R)\n",
      "mupdf: could not parse color space (574 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 --> D:/arXiv//2202.07750.pdf\n",
      "2500 --> D:/arXiv//2202.07954.pdf\n",
      "2600 --> D:/arXiv//2202.08176.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (116 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 --> D:/arXiv//2202.08432.pdf\n",
      "2800 --> D:/arXiv//2202.08633.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (496 0 R)\n",
      "mupdf: could not parse color space (536 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 --> D:/arXiv//2202.08894.pdf\n",
      "3000 --> D:/arXiv//2202.09095.pdf\n",
      "3100 --> D:/arXiv//2202.09318.pdf\n",
      "3200 --> D:/arXiv//2202.09549.pdf\n",
      "3300 --> D:/arXiv//2202.09773.pdf\n",
      "3400 --> D:/arXiv//2202.09989.pdf\n",
      "3500 --> D:/arXiv//2202.10222.pdf\n",
      "3600 --> D:/arXiv//2202.10464.pdf\n",
      "3700 --> D:/arXiv//2202.10680.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (652 0 R)\n",
      "mupdf: could not parse color space (747 0 R)\n",
      "mupdf: could not parse color space (801 0 R)\n",
      "mupdf: could not parse color space (859 0 R)\n",
      "mupdf: could not parse color space (904 0 R)\n",
      "mupdf: could not parse color space (1167 0 R)\n",
      "mupdf: cannot find XObject resource 'arial-minus'\n",
      "mupdf: cannot find XObject resource 'arial-minus'\n",
      "mupdf: cannot find XObject resource 'arial-minus'\n",
      "mupdf: cannot find XObject resource 'arial-minus'\n",
      "mupdf: ICC profile (N=3) is not Gray\n",
      "mupdf: ICC profile (N=3) is not Gray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800 --> D:/arXiv//2202.10894.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (290 0 R)\n",
      "mupdf: could not parse color space (4340 0 R)\n",
      "mupdf: could not parse color space (4378 0 R)\n",
      "mupdf: could not parse color space (14136 0 R)\n",
      "mupdf: could not parse color space (16093 0 R)\n",
      "mupdf: could not parse color space (24393 0 R)\n",
      "mupdf: could not parse color space (24480 0 R)\n",
      "mupdf: could not parse color space (24550 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900 --> D:/arXiv//2202.11134.pdf\n",
      "4000 --> D:/arXiv//2202.11342.pdf\n",
      "4100 --> D:/arXiv//2202.11598.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cmsOpenProfileFromMem failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 --> D:/arXiv//2202.11838.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: unknown keyword: '0.93,'\n",
      "mupdf: unknown keyword: '0.57,'\n",
      "mupdf: unknown keyword: '0.93,'\n",
      "mupdf: unknown keyword: '0.57,'\n",
      "mupdf: unknown keyword: '1.0,'\n",
      "mupdf: unknown keyword: '0.88,'\n",
      "mupdf: unknown keyword: '1.0,'\n",
      "mupdf: unknown keyword: '0.88,'\n",
      "mupdf: could not parse color space (762 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300 --> D:/arXiv//2202.12042.pdf\n",
      "4400 --> D:/arXiv//2202.12269.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: could not parse color space (103 0 R)\n",
      "mupdf: could not parse color space (103 0 R)\n",
      "mupdf: could not parse color space (242 0 R)\n",
      "mupdf: could not parse color space (464 0 R)\n",
      "mupdf: could not parse color space (834 0 R)\n",
      "mupdf: could not parse color space (1854 0 R)\n",
      "mupdf: could not parse color space (2330 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 --> D:/arXiv//2202.12477.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (167 0 R)\n",
      "mupdf: could not parse color space (380 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600 --> D:/arXiv//2202.12694.pdf\n",
      "4700 --> D:/arXiv//2202.12935.pdf\n",
      "4800 --> D:/arXiv//2202.13114.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (287 0 R)\n",
      "mupdf: expected object number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 --> D:/arXiv//2202.13328.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (877 0 R)\n",
      "mupdf: could not parse color space (2009 0 R)\n",
      "mupdf: could not parse color space (2143 0 R)\n",
      "mupdf: could not parse color space (1117 0 R)\n",
      "mupdf: could not parse color space (1174 0 R)\n",
      "mupdf: could not parse color space (1232 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 --> D:/arXiv//2202.13521.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (131 0 R)\n",
      "mupdf: could not parse color space (244 0 R)\n",
      "mupdf: could not parse color space (407 0 R)\n",
      "mupdf: could not parse color space (595 0 R)\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100 --> D:/arXiv//2202.13727.pdf\n",
      "5200 --> D:/arXiv//2202.13958.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: cannot create appearance stream for Screen annotations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300 --> D:/arXiv//2203.00141.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n",
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 --> D:/arXiv//2203.00355.pdf\n",
      "5500 --> D:/arXiv//2203.00554.pdf\n",
      "5600 --> D:/arXiv//2203.00795.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (256 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700 --> D:/arXiv//2203.00970.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (248 0 R)\n",
      "mupdf: could not parse color space (63 0 R)\n",
      "mupdf: could not parse color space (63 0 R)\n",
      "mupdf: cmsOpenProfileFromMem failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5800 --> D:/arXiv//2203.01183.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (291 0 R)\n",
      "mupdf: could not parse color space (682 0 R)\n",
      "mupdf: could not parse color space (1017 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5900 --> D:/arXiv//2203.01416.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (59 0 R)\n",
      "mupdf: could not parse color space (59 0 R)\n",
      "mupdf: could not parse color space (401 0 R)\n",
      "mupdf: could not parse color space (463 0 R)\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 --> D:/arXiv//2203.01608.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cmsOpenProfileFromMem failed\n",
      "mupdf: cmsOpenProfileFromMem failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6100 --> D:/arXiv//2203.01829.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: unknown keyword: 'ca'\n",
      "mupdf: could not parse color space (158 0 R)\n",
      "mupdf: could not parse color space (158 0 R)\n",
      "mupdf: could not parse color space (565 0 R)\n",
      "mupdf: could not parse color space (753 0 R)\n",
      "mupdf: could not parse color space (950 0 R)\n",
      "mupdf: could not parse color space (1190 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6200 --> D:/arXiv//2203.02054.pdf\n",
      "6300 --> D:/arXiv//2203.02226.pdf\n",
      "6400 --> D:/arXiv//2203.02502.pdf\n",
      "6500 --> D:/arXiv//2203.02725.pdf\n",
      "6600 --> D:/arXiv//2203.02958.pdf\n",
      "6700 --> D:/arXiv//2203.03189.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (582 0 R)\n",
      "mupdf: could not parse color space (1023 0 R)\n",
      "mupdf: could not parse color space (1193 0 R)\n",
      "mupdf: could not parse color space (2488 0 R)\n",
      "mupdf: could not parse color space (2685 0 R)\n",
      "mupdf: could not parse color space (2918 0 R)\n",
      "mupdf: could not parse color space (4203 0 R)\n",
      "mupdf: could not parse color space (4308 0 R)\n",
      "mupdf: could not parse color space (4472 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800 --> D:/arXiv//2203.03429.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (393 0 R)\n",
      "mupdf: could not parse color space (261 0 R)\n",
      "mupdf: could not parse color space (315 0 R)\n",
      "mupdf: could not parse color space (378 0 R)\n",
      "mupdf: could not parse color space (288 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6900 --> D:/arXiv//2203.03627.pdf\n",
      "7000 --> D:/arXiv//2203.03854.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n",
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7100 --> D:/arXiv//2203.04050.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: ICC profile (N=3) is not Gray\n",
      "mupdf: could not parse color space (127 0 R)\n",
      "mupdf: could not parse color space (127 0 R)\n",
      "mupdf: could not parse color space (186 0 R)\n",
      "mupdf: could not parse color space (233 0 R)\n",
      "mupdf: could not parse color space (310 0 R)\n",
      "mupdf: could not parse color space (423 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200 --> D:/arXiv//2203.04290.pdf\n",
      "7300 --> D:/arXiv//2203.04502.pdf\n",
      "7400 --> D:/arXiv//2203.04729.pdf\n",
      "7500 --> D:/arXiv//2203.04950.pdf\n",
      "7600 --> D:/arXiv//2203.05187.pdf\n",
      "7700 --> D:/arXiv//2203.05438.pdf\n",
      "7800 --> D:/arXiv//2203.05723.pdf\n",
      "7900 --> D:/arXiv//2203.05952.pdf\n",
      "8000 --> D:/arXiv//2203.06228.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (78 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100 --> D:/arXiv//2203.06456.pdf\n",
      "8200 --> D:/arXiv//2203.06692.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: cannot create appearance stream for Screen annotations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8300 --> D:/arXiv//2203.06951.pdf\n",
      "8400 --> D:/arXiv//2203.07172.pdf\n",
      "8500 --> D:/arXiv//2203.07483.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n",
      "mupdf: invalid key in dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8600 --> D:/arXiv//2203.07686.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (53 0 R)\n",
      "mupdf: could not parse color space (53 0 R)\n",
      "mupdf: could not parse color space (373 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700 --> D:/arXiv//2203.07918.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (744 0 R)\n",
      "mupdf: could not parse color space (1118 0 R)\n",
      "mupdf: object (294 0 R) was not found in its object stream\n",
      "mupdf: object (294 0 R) was not found in its object stream\n",
      "mupdf: object (294 0 R) was not found in its object stream\n",
      "mupdf: object (294 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (294 0 R)\n",
      "mupdf: object (343 0 R) was not found in its object stream\n",
      "mupdf: object (343 0 R) was not found in its object stream\n",
      "mupdf: object (343 0 R) was not found in its object stream\n",
      "mupdf: object (343 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (343 0 R)\n",
      "mupdf: object (486 0 R) was not found in its object stream\n",
      "mupdf: object (486 0 R) was not found in its object stream\n",
      "mupdf: object (486 0 R) was not found in its object stream\n",
      "mupdf: object (486 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (486 0 R)\n",
      "mupdf: object (554 0 R) was not found in its object stream\n",
      "mupdf: object (554 0 R) was not found in its object stream\n",
      "mupdf: object (554 0 R) was not found in its object stream\n",
      "mupdf: object (554 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (554 0 R)\n",
      "mupdf: object (591 0 R) was not found in its object stream\n",
      "mupdf: object (591 0 R) was not found in its object stream\n",
      "mupdf: object (591 0 R) was not found in its object stream\n",
      "mupdf: object (591 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (591 0 R)\n",
      "mupdf: object (641 0 R) was not found in its object stream\n",
      "mupdf: object (641 0 R) was not found in its object stream\n",
      "mupdf: object (641 0 R) was not found in its object stream\n",
      "mupdf: object (641 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (641 0 R)\n",
      "mupdf: object (704 0 R) was not found in its object stream\n",
      "mupdf: object (704 0 R) was not found in its object stream\n",
      "mupdf: object (704 0 R) was not found in its object stream\n",
      "mupdf: object (704 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (704 0 R)\n",
      "mupdf: object (741 0 R) was not found in its object stream\n",
      "mupdf: object (741 0 R) was not found in its object stream\n",
      "mupdf: object (741 0 R) was not found in its object stream\n",
      "mupdf: object (741 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (741 0 R)\n",
      "mupdf: object (776 0 R) was not found in its object stream\n",
      "mupdf: object (776 0 R) was not found in its object stream\n",
      "mupdf: object (776 0 R) was not found in its object stream\n",
      "mupdf: object (776 0 R) was not found in its object stream\n",
      "mupdf: could not parse color space (776 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800 --> D:/arXiv//2203.08148.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (311 0 R)\n",
      "mupdf: could not parse color space (201 0 R)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8900 --> D:/arXiv//2203.08403.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n",
      "mupdf: unknown keyword: 'pagesize'\n",
      "mupdf: unknown keyword: 'width'\n",
      "mupdf: unknown keyword: '614.295pt'\n",
      "mupdf: unknown keyword: 'height'\n",
      "mupdf: unknown keyword: '794.96999pt'\n",
      "mupdf: could not parse color space (174 0 R)\n",
      "mupdf: could not parse color space (751 0 R)\n",
      "mupdf: cannot create appearance stream for Screen annotations\n",
      "mupdf: cannot create appearance stream for Screen annotations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 --> D:/arXiv//2203.08594.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: could not parse color space (281 0 R)\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n",
      "mupdf: unknown keyword: '\\whiteCOLOR'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9100 --> D:/arXiv//2203.08877.pdf\n",
      "9200 --> D:/arXiv//2203.09070.pdf\n",
      "9300 --> D:/arXiv//2203.09279.pdf\n",
      "9400 --> D:/arXiv//2203.09507.pdf\n"
     ]
    }
   ],
   "source": [
    "text_24,meta_out=create_corpus(doclist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4339861\n",
      "4339861\n"
     ]
    }
   ],
   "source": [
    "print(len(meta_out))\n",
    "print(len(text_24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_meta(metainfo):\n",
    "    out=[]\n",
    "    for meta_index,meta_i in enumerate(metainfo):\n",
    "        meta_i[\"index\"]=meta_index\n",
    "        meta_i[\"_id\"]=meta_index\n",
    "        out.append(meta_i)\n",
    "    return(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info=reindex_meta(meta_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smart Households Demand Response Management  ',\n",
       " 'with Micro Grid  ',\n",
       " 'Hossein Mohammadi Ruzbahani, Abolfazl Rahimnejad, Hadis Karimipour  ',\n",
       " 'School of Engineering  University of Guelph  ',\n",
       " 'Guelph, Canada  ',\n",
       " '{hkarimi, hmoham15, arahimne}@uoguelph.ca  ',\n",
       " 'Abstract— Nowadays the emerging smart grid technology opens  up the possibility of two-way communication between customers  and energy utilities. Demand Response Management (DRM)  offers the promise of saving money for commercial customers  and households while helps utilities operate more efficiently. In  this paper, an Incentive-based Demand Response Optimization  (IDRO) model is proposed to efficiently schedule household  appliances for minimum usage during peak hours. The proposed  method is a multi-objective optimization technique based on  Nonlinear Auto-Regressive Neural Network (NAR-NN) which  considers energy provided by the utility and rooftop installed  photovoltaic (PV) system. The proposed method is tested and  verified using 300 case studies (household). Data analysis for a  period of one year shows a noticeable improvement in power  factor and customers’ bill.  ',\n",
       " 'Keywords— demand response management, optimization, peak  hour, smart home, smart grids.    ',\n",
       " 'NOMENCLATURE  ',\n",
       " '𝑚         Total number of uninterruptible loads  𝐻          Time slot, 30 minutes  𝑃𝐶 ',\n",
       " '𝑡         Value of actual consumption at time t    ',\n",
       " '𝑡         The objective curve at time t  ',\n",
       " '𝐷𝑠         Customer’s discomfort associated with a delay  𝑑𝑠         Customer discomfort associated with a shift  𝑥𝑛𝑠         Binary variables for device s in time slot n  𝑃𝑠ℎ𝑚 ',\n",
       " '𝐻      Consumption of device m in time slot H  ',\n",
       " '𝐵𝐻        Solar cell operating status (Binary) in time slot H  𝑇𝐴𝑝𝑝𝑖     Operation time of device i  ℎ𝐴𝑝𝑝𝑖    Operation time slots of the device i   𝑃𝐵𝑆𝐿 ',\n",
       " '𝐻       Solar cell battery charge level in time slot H  ']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_24[0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 0,\n",
       "  'index': 0,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 59,\n",
       "  'pos1': 55,\n",
       "  'pos2': 558,\n",
       "  'pos3': 81},\n",
       " {'_id': 1,\n",
       "  'index': 1,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 227,\n",
       "  'pos1': 82,\n",
       "  'pos2': 390,\n",
       "  'pos3': 109},\n",
       " {'_id': 2,\n",
       "  'index': 2,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 141,\n",
       "  'pos1': 127,\n",
       "  'pos2': 473,\n",
       "  'pos3': 139},\n",
       " {'_id': 3,\n",
       "  'index': 3,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 261,\n",
       "  'pos1': 139,\n",
       "  'pos2': 353,\n",
       "  'pos3': 162},\n",
       " {'_id': 4,\n",
       "  'index': 4,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 273,\n",
       "  'pos1': 162,\n",
       "  'pos2': 340,\n",
       "  'pos3': 173},\n",
       " {'_id': 5,\n",
       "  'index': 5,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 210,\n",
       "  'pos1': 174,\n",
       "  'pos2': 403,\n",
       "  'pos3': 185},\n",
       " {'_id': 6,\n",
       "  'index': 6,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 51,\n",
       "  'pos1': 206,\n",
       "  'pos2': 299,\n",
       "  'pos3': 360},\n",
       " {'_id': 7,\n",
       "  'index': 7,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 51,\n",
       "  'pos1': 367,\n",
       "  'pos2': 299,\n",
       "  'pos3': 387},\n",
       " {'_id': 8,\n",
       "  'index': 8,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 51,\n",
       "  'pos1': 394,\n",
       "  'pos2': 124,\n",
       "  'pos3': 405},\n",
       " {'_id': 9,\n",
       "  'index': 9,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 51,\n",
       "  'pos1': 409,\n",
       "  'pos2': 232,\n",
       "  'pos3': 445},\n",
       " {'_id': 10,\n",
       "  'index': 10,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 57,\n",
       "  'pos1': 432,\n",
       "  'pos2': 239,\n",
       "  'pos3': 443},\n",
       " {'_id': 11,\n",
       "  'index': 11,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 57,\n",
       "  'pos1': 444,\n",
       "  'pos2': 198,\n",
       "  'pos3': 455},\n",
       " {'_id': 12,\n",
       "  'index': 12,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 51,\n",
       "  'pos1': 455,\n",
       "  'pos2': 269,\n",
       "  'pos3': 503},\n",
       " {'_id': 13,\n",
       "  'index': 13,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 57,\n",
       "  'pos1': 486,\n",
       "  'pos2': 240,\n",
       "  'pos3': 501},\n",
       " {'_id': 14,\n",
       "  'index': 14,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 51,\n",
       "  'pos1': 502,\n",
       "  'pos2': 278,\n",
       "  'pos3': 551},\n",
       " {'_id': 15,\n",
       "  'index': 15,\n",
       "  'fname': '1907.03641',\n",
       "  'page': 0,\n",
       "  'pos0': 57,\n",
       "  'pos1': 536,\n",
       "  'pos2': 258,\n",
       "  'pos3': 550}]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_out[0:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mongo_col.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mongo_col.insert_many(meta_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bekezdések száma: 4339861\n"
     ]
    }
   ],
   "source": [
    "print(f\"bekezdések száma: {len(text_24)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sipocz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sipocz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cov difference w.r.t. domain 1 test set '"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_24[-1119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nregexp_digits_dot_digits = re.compile(r\\'^(\\\\d+(\\\\.+\\\\d+)*(\\\\.)*)$\\')\\ncorpus_text = \"\".join(text_24[:])\\nprint(\"start\")\\ndata_token = []\\nst=[]\\nfor i in range(0,171):\\n    print(f\"index:{i}\", end=\",\")\\n    stx=sent_tokenize(corpus_text[i*1000000:(i+1)*1000000])\\n    st=st+stx\\nprint(\"tokenized\")\\n# iterate over each sentence in the document for i in sent_tokenize(corpus_text):\\n'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "'''\n",
    "regexp_digits_dot_digits = re.compile(r'^(\\d+(\\.+\\d+)*(\\.)*)$')\n",
    "corpus_text = \"\".join(text_24[:])\n",
    "print(\"start\")\n",
    "data_token = []\n",
    "st=[]\n",
    "for i in range(0,171):\n",
    "    print(f\"index:{i}\", end=\",\")\n",
    "    stx=sent_tokenize(corpus_text[i*1000000:(i+1)*1000000])\n",
    "    st=st+stx\n",
    "print(\"tokenized\")\n",
    "# iterate over each sentence in the document for i in sent_tokenize(corpus_text):\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smart Households Demand Response Management']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text_24[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4339861\n"
     ]
    }
   ],
   "source": [
    "print(len(text_24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4339861\n"
     ]
    }
   ],
   "source": [
    "print(len(meta_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Smart Households Demand Response Management  '"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_24[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4339861\n"
     ]
    }
   ],
   "source": [
    "print(len(text_24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smart', 'Households', 'Demand', 'Response', 'Management']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text_24[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nindex_i=0\\nfor i in st:\\n    index_i=index_i+1\\n    if index_i % 100000==0:\\n        print(index_i,end=\",\")\\n    temp = []\\n    # tokenize the sentence into words\\n    for j in word_tokenize(i):\\n        if not re.match(regexp_digits_dot_digits, j):    # ITT KIESHETNEK ADATOK !!\\n            temp.append(j.lower())\\n        else:\\n            #print(j,end=\" \") # \\n            pass\\n    data_token.append(temp)\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "index_i=0\n",
    "for i in st:\n",
    "    index_i=index_i+1\n",
    "    if index_i % 100000==0:\n",
    "        print(index_i,end=\",\")\n",
    "    temp = []\n",
    "    # tokenize the sentence into words\n",
    "    for j in word_tokenize(i):\n",
    "        if not re.match(regexp_digits_dot_digits, j):    # ITT KIESHETNEK ADATOK !!\n",
    "            temp.append(j.lower())\n",
    "        else:\n",
    "            #print(j,end=\" \") # \n",
    "            pass\n",
    "    data_token.append(temp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['𝑃𝑠ℎ𝑚']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text_24[123],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_generator(text_in:str):\n",
    "    import re\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    # text_24 converter  text_24: stringek listája -> listák listája\n",
    "    regexp_digits_dot_digits = re.compile(r'(\\d+(\\.+\\d+)*(\\.)*)')\n",
    "    regexp_digits = re.compile(r'( |^)(\\d+)( |\\.|\\,|\\(|\\))')\n",
    "    regexp_comma=re.compile(r\"(\\,|\\:|\\<|\\>|\\”|\\“|\\™|\\(|\\)|\\—|\\?)\")\n",
    "    \n",
    "    \n",
    "    def inline_image(textin):\n",
    "        if (\"image\" in textin) and  ('bpc' in textin):\n",
    "            return(\"_image_\")\n",
    "        else:\n",
    "            return(textin)\n",
    "    \n",
    "    def concat(lst:list):\n",
    "        '''\n",
    "        az elválasztásokat összerakja\n",
    "        '''\n",
    "        o=lst[:]\n",
    "        i=0\n",
    "        while i < len(o):\n",
    "            #print(f\"{i}. {o}\")\n",
    "            \n",
    "            if o[i][-1]==\"-\" and i<len(o)-1:\n",
    "                o[i]=o[i][:-1]+o[i+1][:]\n",
    "                del o[i+1]\n",
    "            i+=1    \n",
    "        return(o)\n",
    "    temp1=text_in.lower()    #print(j,end=\" \")\n",
    "    temp1=inline_image(temp1)\n",
    "    temp2=re.sub(regexp_digits_dot_digits,\"_digit_digit_\",temp1)   #\n",
    "    temp3=re.sub(regexp_digits,\"_data_\",temp2)   #\n",
    "        \n",
    "        \n",
    "    temp4=temp3.replace(\".\",\"\")\n",
    "    temp5=re.sub(regexp_comma,\"\",temp4)\n",
    "\n",
    "    temp6=word_tokenize(temp5)\n",
    "        \n",
    "    temp7=concat(temp6)\n",
    "    temp8=[lemmatizer.lemmatize(i) for i in temp7]\n",
    "\n",
    "\n",
    "    return(temp8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['application',\n",
       " 'consequtives',\n",
       " 'wolf',\n",
       " \"'s\",\n",
       " 't_digit_digit_',\n",
       " 's_digit_digit_xa',\n",
       " '_digit_digit_a']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_generator(\"Applications consequtives wolf's T72 s800xa 713a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_24_converter(text_24):\n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    index_i=0\n",
    "    data_token=[]\n",
    "    for text_i in text_24[:]:\n",
    "        index_i=index_i+1\n",
    "        # tokenize the sentence into words\n",
    "        \n",
    "        lemma=lemma_generator(text_i)\n",
    "        \n",
    "        if index_i % 100000==0:\n",
    "            print(index_i,end=\",\")\n",
    "        \n",
    "            print(lemma)\n",
    "            \n",
    "        \n",
    "        data_token.append(lemma)\n",
    "    return(data_token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_test=text_24_converter(text_24[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000,['_digit_digit_']\n",
      "200000,['b', 'direction', 'plot', 'fairnf']\n",
      "300000,['_image_']\n",
      "400000,['_image_']\n",
      "500000,['apart', 'from', 'the', 'other', 'condition', 'for', 'structured', 'assertion', 'we', 'demand', 'that', 'each', 'ui', '∈', 'varspat', '∪', 'n', 'the', 'public', 'term', 'of', 'α', 'are', 'deﬁned', 'a']\n",
      "600000,['f', 'out', 'gas', '=', 'f', 'in', 'gas', 'a_digit_digit_']\n",
      "700000,['launch']\n",
      "800000,['_digit_digit_', 'recognition', 'many', 'participant', 'considered', 'whether', 'the', 'action', 'would', 'be', 'too', 'subtle', 'for', 'the', 'phone', 'to', 'recognize']\n",
      "900000,['by', 'claim', '_digit_digit_', 'for', 'every', '�𝑥', '∈', 'r𝐵𝑛', 'there', 'exists', '�𝑥', '′', '∈', 'u𝑛𝐵', 'that', 'is', 'no', 'more', 'than', '𝐶′', 'away', 'from', '�𝑥', 'in', '𝐿∞', 'because', 'vector', 'in', 'r𝐵𝑛', 'are', 'at', 'least', '_digit_digit_𝐶′', 'away', 'from', 'each', 'other', 'their', 'corresponding', 'vector', 'in', 'u𝑛𝐵', 'are', 'different', 'denoted', 'by', 'rz', '𝐵𝑛', 'and', 'is', 'formally', 'defined', 'a', 'follows']\n",
      "1000000,['method', 'acc', 'rem', 'm', 'te', 'f', 'clscore', 'clstability']\n",
      "1100000,['i=_digit_digit_']\n",
      "1200000,['_digit_digit_', '_digit_digit_', '_digit_digit_', '_digit_digit_', '_digit_digit_', 'frequency', 'bin']\n",
      "1300000,['_image_']\n",
      "1400000,['|g|', 'where', 'ps𝑘', '=']\n",
      "1500000,['_image_']\n",
      "1600000,['discopopper']\n",
      "1700000,['and', 'number', 'of', 'path', 'l', '=', '{', '_digit_digit_', '_digit_digit_', '}', 'where', 'l', '=', '_digit_digit_', 'mean', 'that', 'only', 'los', 'link', 'exists', 'parameter', 'ptx', '=', '_digit_digit_', 'db', 'nf', '=', '_digit_digit_db']\n",
      "1800000,['∗∗', 'and', 'orthographic', 'hemisphere']\n",
      "1900000,['_digit_digit_', 'acknowledgment']\n",
      "2000000,['_image_']\n",
      "2100000,['_image_']\n",
      "2200000,['_image_']\n",
      "2300000,['_digit_digit_', 'for', 'any', 'c′', '_digit_digit_', 'with', 'probability', 'at', 'least', '_digit_digit_−on−c′', 'ψ', 'fails', 'to', 'distinguish', 'at', 'least', 'a', '_digit_digit_·φck_digit_digit_', 'fraction', 'of', 'the', 'inter-edges', 'from', 'the', 'intra-edges']\n",
      "2400000,['to', 'promote', 'a', 'product/service', 'or', 'several', 'products/services', 'together', 'eg', 'boot', 'on', 'a']\n",
      "2500000,['_image_']\n",
      "2600000,['conference', 'on', 'machine', 'learning', '_digit_digit_']\n",
      "2700000,['_image_']\n",
      "2800000,['_digit_digit_']\n",
      "2900000,['𝑗=_digit_digit_', '𝜇𝑗']\n",
      "3000000,['_digit_digit_', 'solution']\n",
      "3100000,['_digit_digit_', 'roder', 'm', 'passos', 'la', 'ribeiro', 'lcf', 'benato', 'bc', 'falc˜ao', 'al', 'papa', 'jp', 'intestinal', 'parasite', 'classiﬁcation', 'using', 'deep', 'belief', 'network', 'in', 'the', '_digit_digit_th', 'international', 'conference', 'on', 'artiﬁcial', 'intelligence', 'and', 'soft', 'computing', 'icaisc', 'ieee', 'in', 'press', '_digit_digit_', 'roder', 'm', 'de', 'rosa', 'gh', 'de', 'albuquerque', 'vhc', 'rossi', 'aeld', 'papa', 'jap', 'energy-based', 'dropout', 'in', 'restricted', 'boltzmann', 'machine', 'why', 'not', 'go', 'random', 'ieee', 'transaction', 'on', 'emerging', 'topic', 'in', 'computational', 'intelligence', 'pp', '_digit_digit_–_digit_digit_', '_digit_digit_', 'https//doiorg/_digit_digit_/tetci_digit_digit_', '_digit_digit_', 'santana', 'mc', 'passos', 'la', 'moreira', 'tp', 'colombo', 'd', 'de', 'albuquerque', 'vhc', 'papa', 'jp', 'a', 'novel', 'siamese-based', 'approach', 'for', 'scene', 'change', 'detection', 'with', 'application', 'to', 'obstructed', 'route', 'in', 'hazardous', 'environment', 'ieee', 'intelligent', 'system', '_digit_digit__digit_digit_', '_digit_digit_–_digit_digit_', '_digit_digit_', '_digit_digit_', 'santos', 'cfgd', 'colombo', 'd', 'roder', 'm', 'papa', 'jp', 'maxdropout', 'deep', 'neural', 'network', 'regularization', 'based', 'on', 'maximum', 'output', 'value', 'in', 'proceeding', 'of', '_digit_digit_th', 'international', 'conference', 'on', 'pattern', 'recognition', 'icpr', '_digit_digit_', 'milan', 'italy', '_digit_digit_-_digit_digit_', 'january', '_digit_digit_', 'pp', '_digit_digit_–_digit_digit_', 'ieee', 'computer', 'society', '_digit_digit_', '_digit_digit_', 'simon', 'm', 'rodner', 'e', 'denzler', 'j', 'imagenet', 'pre-trained', 'model', 'with', 'batch', 'normalization', 'arxiv', 'preprint', 'arxiv_digit_digit_', '_digit_digit_', '_digit_digit_', 'srivastava', 'n', 'hinton', 'g', 'krizhevsky', 'a', 'sutskever', 'i', 'salakhutdinov', 'r', 'dropout', 'a', 'simple', 'way', 'to', 'prevent', 'neural', 'network', 'from', 'overﬁtting', 'the', 'journal', 'of', 'machine', 'learning', 'research', '_digit_digit__digit_digit_', '_digit_digit_–_digit_digit_', '_digit_digit_', '_digit_digit_', 'srivastava', 'n', 'hinton', 'g', 'krizhevsky', 'a', 'sutskever', 'i', 'salakhutdinov', 'r', 'dropout', 'a', 'simple', 'way', 'to', 'prevent', 'neural', 'network', 'from', 'overﬁtting', 'the', 'journal', 'of', 'machine', 'learning', 'research', '_digit_digit__digit_digit_', '_digit_digit_–_digit_digit_', '_digit_digit_', '_digit_digit_', 'sun', 'z', 'he', 's', 'idiopathic', 'interstitial', 'pneumonia', 'medical', 'image', 'detection', 'using', 'deep', 'learning', 'technique', 'a', 'survey', 'in', 'proceeding', 'of', 'the', '_digit_digit_', 'acm', 'southeast', 'conference', 'pp', '_digit_digit_–_digit_digit_', '_digit_digit_', '_digit_digit_', 'tan', 'm', 'le', 'qv', 'eﬃcientnet', 'rethinking', 'model', 'scaling', 'for', 'convolutional', 'neural', 'network', 'arxiv', 'preprint', 'arxiv_digit_digit_', '_digit_digit_', '_digit_digit_', 'wang', 'j', 'hu', 'x', 'gated', 'recurrent', 'convolution', 'neural', 'network', 'for', 'ocr', 'in', 'advance', 'in', 'neural', 'information', 'processing', 'system', 'pp', '_digit_digit_–_digit_digit_', '_digit_digit_', '_digit_digit_', 'wang', 's', 'manning', 'c', 'fast', 'dropout', 'training', 'in', 'international', 'conference', 'on', 'machine', 'learning', 'pp', '_digit_digit_–_digit_digit_', '_digit_digit_', '_digit_digit_', 'zhang', 'k', 'zuo', 'w', 'chen', 'y', 'meng', 'd', 'zhang', 'l', 'beyond', 'a', 'gaussian', 'denoiser', 'residual', 'learning', 'of', 'deep', 'cnn', 'for', 'image', 'denoising', 'ieee', 'transaction', 'on', 'image', 'processing', '_digit_digit__digit_digit_', '_digit_digit_–_digit_digit_', '_digit_digit_', '_digit_digit_', 'zhong', 'z', 'zheng', 'l', 'kang', 'g', 'li', 's', 'yang', 'y', 'random', 'erasing', 'data', 'augmentation', 'in', 'proceeding', 'of', 'the', 'aaai', 'conference', 'on', 'artiﬁcial', 'intelligence', 'aaai', '_digit_digit_', '_digit_digit_', 'zhong', 'z', 'zheng', 'l', 'kang', 'g', 'li', 's', 'yang', 'y', 'random', 'erasing', 'data', 'augmentation', 'in', 'aaai', 'pp', '_digit_digit_–_digit_digit_', '_digit_digit_']\n",
      "3200000,['pitest']\n",
      "3300000,['in', 'the', 'black-box', 'scenario', 'to', 'keep', 'stealthy', 'another', 'important', 'concern', 'is', 'how', 'many', 'query', 'should', 'be', 'performed', 'we', 'investigate', 'this', 'point', 'in', 'tab', '_digit_digit_', 'from', 'which', 'it', 'can', 'be', 'found', 'that', 'our', 'method', 'can', 'get', 'a', 'valid', 'adversarial', 'example', 'with', 'only', 'dozen', 'or', 'hundred', 'of', 'query']\n",
      "3400000,['_image_']\n",
      "3500000,['kihyuk', 'sohn', 'improved', 'deep', 'metric', 'learning', 'with', 'multi-class', 'n-pair', 'loss', 'objective', 'in', 'nip', 'page', '_digit_digit_–_digit_digit_', '_digit_digit_']\n",
      "3600000,['fϕ', '∈', 'pκ', 'such', 'that', 'for', 'every', 'g', '∈', 'pκ', 'ϕg', '=', '�']\n",
      "3700000,['k-mnist', 'prediction', 'acc', '=', '_digit_digit_', '%']\n",
      "3800000,['by', 'assumption', 'a_digit_digit_', 'it', 'derives', 'that']\n",
      "3900000,['_image_']\n",
      "4000000,['_digit_digit_', 'problem', 'formulation']\n",
      "4100000,['_image_']\n",
      "4200000,['in', 'the', 'case', 'of', 'avi', 'for', 'the', 'phase', 'ﬁeld', 'approach', 'to', 'fracture', 'a', 'few', 'adjustment', 'need', 'to', 'be', 'made', 'first', 'and', 'foremost', 'the', 'overall', '_digit_digit_']\n",
      "4300000,['fig', '_digit_digit_', 'comparison', 'of', 'ez-vsl', 'with', 'state-of-the-art', 'method', 'on', 'flickr', 'soundnet', '[', '_digit_digit_', ']', 'a', 'and', 'vgg-ss', '[', '_digit_digit_', ']', 'all', 'method', 'in', 'a', 'are', 'trained', 'on', 'flickr', '_digit_digit_k', 'and', 'those', 'in', 'b', 'on', 'vgg', 'sound', '_digit_digit_k']\n"
     ]
    }
   ],
   "source": [
    "data_token=text_24_converter(text_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_version(index_ii):\n",
    "\n",
    "    print(text_24[index_ii])\n",
    "    print(dt_test[index_ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Households Demand Response Management  \n",
      "['smart', 'household', 'demand', 'response', 'management']\n",
      "with Micro Grid  \n",
      "['with', 'micro', 'grid']\n",
      "Hossein Mohammadi Ruzbahani, Abolfazl Rahimnejad, Hadis Karimipour  \n",
      "['hossein', 'mohammadi', 'ruzbahani', 'abolfazl', 'rahimnejad', 'hadis', 'karimipour']\n",
      "School of Engineering  University of Guelph  \n",
      "['school', 'of', 'engineering', 'university', 'of', 'guelph']\n",
      "Guelph, Canada  \n",
      "['guelph', 'canada']\n",
      "{hkarimi, hmoham15, arahimne}@uoguelph.ca  \n",
      "['{', 'hkarimi', 'hmoham_digit_digit_', 'arahimne', '}', '@', 'uoguelphca']\n",
      "Abstract— Nowadays the emerging smart grid technology opens  up the possibility of two-way communication between customers  and energy utilities. Demand Response Management (DRM)  offers the promise of saving money for commercial customers  and households while helps utilities operate more efficiently. In  this paper, an Incentive-based Demand Response Optimization  (IDRO) model is proposed to efficiently schedule household  appliances for minimum usage during peak hours. The proposed  method is a multi-objective optimization technique based on  Nonlinear Auto-Regressive Neural Network (NAR-NN) which  considers energy provided by the utility and rooftop installed  photovoltaic (PV) system. The proposed method is tested and  verified using 300 case studies (household). Data analysis for a  period of one year shows a noticeable improvement in power  factor and customers’ bill.  \n",
      "['abstract', 'nowadays', 'the', 'emerging', 'smart', 'grid', 'technology', 'open', 'up', 'the', 'possibility', 'of', 'two-way', 'communication', 'between', 'customer', 'and', 'energy', 'utility', 'demand', 'response', 'management', 'drm', 'offer', 'the', 'promise', 'of', 'saving', 'money', 'for', 'commercial', 'customer', 'and', 'household', 'while', 'help', 'utility', 'operate', 'more', 'efficiently', 'in', 'this', 'paper', 'an', 'incentive-based', 'demand', 'response', 'optimization', 'idro', 'model', 'is', 'proposed', 'to', 'efficiently', 'schedule', 'household', 'appliance', 'for', 'minimum', 'usage', 'during', 'peak', 'hour', 'the', 'proposed', 'method', 'is', 'a', 'multi-objective', 'optimization', 'technique', 'based', 'on', 'nonlinear', 'auto-regressive', 'neural', 'network', 'nar-nn', 'which', 'considers', 'energy', 'provided', 'by', 'the', 'utility', 'and', 'rooftop', 'installed', 'photovoltaic', 'pv', 'system', 'the', 'proposed', 'method', 'is', 'tested', 'and', 'verified', 'using', '_digit_digit_', 'case', 'study', 'household', 'data', 'analysis', 'for', 'a', 'period', 'of', 'one', 'year', 'show', 'a', 'noticeable', 'improvement', 'in', 'power', 'factor', 'and', 'customer', '’', 'bill']\n",
      "Keywords— demand response management, optimization, peak  hour, smart home, smart grids.    \n",
      "['keywords', 'demand', 'response', 'management', 'optimization', 'peak', 'hour', 'smart', 'home', 'smart', 'grid']\n",
      "NOMENCLATURE  \n",
      "['nomenclature']\n",
      "𝑚         Total number of uninterruptible loads  𝐻          Time slot, 30 minutes  𝑃𝐶 \n",
      "['𝑚', 'total', 'number', 'of', 'uninterruptible', 'load', '𝐻', 'time', 'slot', '_digit_digit_', 'minute', '𝑃𝐶']\n",
      "𝑡         Value of actual consumption at time t    \n",
      "['𝑡', 'value', 'of', 'actual', 'consumption', 'at', 'time', 't']\n",
      "𝑡         The objective curve at time t  \n",
      "['𝑡', 'the', 'objective', 'curve', 'at', 'time', 't']\n",
      "𝐷𝑠         Customer’s discomfort associated with a delay  𝑑𝑠         Customer discomfort associated with a shift  𝑥𝑛𝑠         Binary variables for device s in time slot n  𝑃𝑠ℎ𝑚 \n",
      "['𝐷𝑠', 'customer', '’', 's', 'discomfort', 'associated', 'with', 'a', 'delay', '𝑑𝑠', 'customer', 'discomfort', 'associated', 'with', 'a', 'shift', '𝑥𝑛𝑠', 'binary', 'variable', 'for', 'device', 's', 'in', 'time', 'slot', 'n', '𝑃𝑠ℎ𝑚']\n",
      "𝐻      Consumption of device m in time slot H  \n",
      "['𝐻', 'consumption', 'of', 'device', 'm', 'in', 'time', 'slot', 'h']\n",
      "𝐵𝐻        Solar cell operating status (Binary) in time slot H  𝑇𝐴𝑝𝑝𝑖     Operation time of device i  ℎ𝐴𝑝𝑝𝑖    Operation time slots of the device i   𝑃𝐵𝑆𝐿 \n",
      "['𝐵𝐻', 'solar', 'cell', 'operating', 'status', 'binary', 'in', 'time', 'slot', 'h', '𝑇𝐴𝑝𝑝𝑖', 'operation', 'time', 'of', 'device', 'i', 'ℎ𝐴𝑝𝑝𝑖', 'operation', 'time', 'slot', 'of', 'the', 'device', 'i', '𝑃𝐵𝑆𝐿']\n",
      "𝐻       Solar cell battery charge level in time slot H  \n",
      "['𝐻', 'solar', 'cell', 'battery', 'charge', 'level', 'in', 'time', 'slot', 'h']\n",
      "𝑇𝐵         The time required for the battery to be fully charged   𝑃𝐴𝑙𝑙𝑚 \n",
      "['𝑇𝐵', 'the', 'time', 'required', 'for', 'the', 'battery', 'to', 'be', 'fully', 'charged', '𝑃𝐴𝑙𝑙𝑚']\n",
      "𝐻      Total consumption of all loads in time slot H  \n",
      "['𝐻', 'total', 'consumption', 'of', 'all', 'load', 'in', 'time', 'slot', 'h']\n",
      "𝐷𝑐         Number of devices of type k available for control  𝑃𝐴𝑙𝑙 \n",
      "['𝐷𝑐', 'number', 'of', 'device', 'of', 'type', 'k', 'available', 'for', 'control', '𝑃𝐴𝑙𝑙']\n",
      "𝐻        Total consumption of shiftable devices in the time  \n",
      "['𝐻', 'total', 'consumption', 'of', 'shiftable', 'device', 'in', 'the', 'time']\n",
      "𝑡          Number of fixed devices of type j  \n",
      "['𝑡', 'number', 'of', 'fixed', 'device', 'of', 'type', 'j']\n",
      "𝑃𝑖          Power consumption of the device type i  𝑃𝑃 \n",
      "['𝑃𝑖', 'power', 'consumption', 'of', 'the', 'device', 'type', 'i', '𝑃𝑃']\n",
      "𝑡         Predicted load consumption at time t  \n",
      "['𝑡', 'predicted', 'load', 'consumption', 'at', 'time', 't']\n",
      "𝑃̅𝑜𝑓𝑓      Average consumption during off-load   𝐿𝑚𝑖𝑛      Minimum usage required during off-peak hours  \n",
      "['𝑃̅𝑜𝑓𝑓', 'average', 'consumption', 'during', 'off-load', '𝐿𝑚𝑖𝑛', 'minimum', 'usage', 'required', 'during', 'off-peak', 'hour']\n",
      "𝑃𝑝𝑒𝑟𝑚𝑖𝑡𝑡𝑒𝑑 \n",
      "['𝑃𝑝𝑒𝑟𝑚𝑖𝑡𝑡𝑒𝑑']\n",
      "𝑚𝑎𝑥              Maximum consumption during peak hours  \n",
      "['𝑚𝑎𝑥', 'maximum', 'consumption', 'during', 'peak', 'hour']\n",
      "[𝑇𝑝𝑒𝑎𝑘𝑖 \n",
      "['[', '𝑇𝑝𝑒𝑎𝑘𝑖']\n",
      "𝑆𝑡𝑎𝑟𝑡, 𝑇𝑝𝑒𝑎𝑘𝑖 \n",
      "['𝑆𝑡𝑎𝑟𝑡', '𝑇𝑝𝑒𝑎𝑘𝑖']\n",
      "𝐸𝑛𝑑 ]      Start and end time interval for Peak hour i  \n",
      "['𝐸𝑛𝑑', ']', 'start', 'and', 'end', 'time', 'interval', 'for', 'peak', 'hour', 'i']\n",
      "𝐶𝑃𝑚𝐻                        Number of preferred time slots for shifting  determined  by load m in time slot H  𝑠𝑖 \n",
      "['𝐶𝑃𝑚𝐻', 'number', 'of', 'preferred', 'time', 'slot', 'for', 'shifting', 'determined', 'by', 'load', 'm', 'in', 'time', 'slot', 'h', '𝑠𝑖']\n",
      "𝑡     Number of shiftable devices of type i shifted to time t  \n",
      "['𝑡', 'number', 'of', 'shiftable', 'device', 'of', 'type', 'i', 'shifted', 'to', 'time', 't']\n",
      "𝑡     Number of shiftable devices of type k shifted away  from time t  \n",
      "['𝑡', 'number', 'of', 'shiftable', 'device', 'of', 'type', 'k', 'shifted', 'away', 'from', 'time', 't']\n",
      "I.  INTRODUCTION  \n",
      "['i', 'introduction']\n",
      "      According to the U.S. Department of Energy, demand for  electricity is expected to grow 30% by 2035 as a result of new  consumption models (smart appliances, electric vehicles and  whole house monitoring systems) [1]. Integration of the smart  grid technology into the bulk power system provides the  opportunity for two-way communication between the utility  company  and  end-users  through  Demand  Response  \n",
      "['according', 'to', 'the', 'u', 'department', 'of', 'energy', 'demand', 'for', 'electricity', 'is', 'expected', 'to', 'grow', '_digit_digit_', '%', 'by', '_digit_digit_', 'a', 'a', 'result', 'of', 'new', 'consumption', 'model', 'smart', 'appliance', 'electric', 'vehicle', 'and', 'whole', 'house', 'monitoring', 'system', '[', '_digit_digit_', ']', 'integration', 'of', 'the', 'smart', 'grid', 'technology', 'into', 'the', 'bulk', 'power', 'system', 'provides', 'the', 'opportunity', 'for', 'two-way', 'communication', 'between', 'the', 'utility', 'company', 'and', 'end-users', 'through', 'demand', 'response']\n",
      "Management (DRM) [2]. A detailed study of the potential  impact of residential demand-side management on the cost and  greenhouse gas emissions is presented in [3].  \n",
      "['management', 'drm', '[', '_digit_digit_', ']', 'a', 'detailed', 'study', 'of', 'the', 'potential', 'impact', 'of', 'residential', 'demand-side', 'management', 'on', 'the', 'cost', 'and', 'greenhouse', 'gas', 'emission', 'is', 'presented', 'in', '[', '_digit_digit_', ']']\n",
      "Although the future of DRM depends on automatic control  \n",
      "['although', 'the', 'future', 'of', 'drm', 'depends', 'on', 'automatic', 'control']\n",
      "of residential loads, the end-users play a significant role by  shifting the use of appliances to the off-peak hours [4].  Different techniques are required to act as a bridge between the  consumer and the utility for controlling the load demand  during peak hours. However, in most techniques, incentive- based DR programs play a major role in improving grid  operation and reliability as well as cost management [5].  \n",
      "['of', 'residential', 'load', 'the', 'end-users', 'play', 'a', 'significant', 'role', 'by', 'shifting', 'the', 'use', 'of', 'appliance', 'to', 'the', 'off-peak', 'hour', '[', '_digit_digit_', ']', 'different', 'technique', 'are', 'required', 'to', 'act', 'a', 'a', 'bridge', 'between', 'the', 'consumer', 'and', 'the', 'utility', 'for', 'controlling', 'the', 'load', 'demand', 'during', 'peak', 'hour', 'however', 'in', 'most', 'technique', 'incentivebased', 'dr', 'program', 'play', 'a', 'major', 'role', 'in', 'improving', 'grid', 'operation', 'and', 'reliability', 'a', 'well', 'a', 'cost', 'management', '[', '_digit_digit_', ']']\n",
      "Most of the researches on DRM are limited to high voltage  \n",
      "['most', 'of', 'the', 'research', 'on', 'drm', 'are', 'limited', 'to', 'high', 'voltage']\n",
      "levels, such as industrial loads [6]. There are few studies  focused on the household sector [7]. In most of the proposed  methods, customers’ common welfare, utility costs, efficient  operation, the cost of required communication infrastructure,  and the probability of cyber-attack are neglected and generally  focuses on only a single objective [8]. Some load control  strategies for shedding household appliances [9] and several  scheduling methods for mitigating residential power  consumption [10]-[12] have been proposed in the past.  \n",
      "['level', 'such', 'a', 'industrial', 'load', '[', '_digit_digit_', ']', 'there', 'are', 'few', 'study', 'focused', 'on', 'the', 'household', 'sector', '[', '_digit_digit_', ']', 'in', 'most', 'of', 'the', 'proposed', 'method', 'customer', '’', 'common', 'welfare', 'utility', 'cost', 'efficient', 'operation', 'the', 'cost', 'of', 'required', 'communication', 'infrastructure', 'and', 'the', 'probability', 'of', 'cyber-attack', 'are', 'neglected', 'and', 'generally', 'focus', 'on', 'only', 'a', 'single', 'objective', '[', '_digit_digit_', ']', 'some', 'load', 'control', 'strategy', 'for', 'shedding', 'household', 'appliance', '[', '_digit_digit_', ']', 'and', 'several', 'scheduling', 'method', 'for', 'mitigating', 'residential', 'power', 'consumption', '[', '_digit_digit_', ']', '[', '_digit_digit_', ']', 'have', 'been', 'proposed', 'in', 'the', 'past']\n",
      "However, this study proposes an intelligent and flexible  \n",
      "['however', 'this', 'study', 'proposes', 'an', 'intelligent', 'and', 'flexible']\n",
      "algorithm for DRM considering the combined source of  energy, including electricity provided by the utility and rooftop  \n",
      "['algorithm', 'for', 'drm', 'considering', 'the', 'combined', 'source', 'of', 'energy', 'including', 'electricity', 'provided', 'by', 'the', 'utility', 'and', 'rooftop']\n",
      "installed residential photovoltaic (PV) system. The main  contribution of this paper is the development of a scheduling  algorithm (multi-objective optimization with NAR-NN) to  minimize the electricity bill and customer’s discomfort  considering the operational dynamics of non-schedulable loads  and electricity price variation. To avoid consumer's  discomfort, a scheduling algorithm is applied, using historical  data of the consumer's habits and PV generation forecasts.  \n",
      "['installed', 'residential', 'photovoltaic', 'pv', 'system', 'the', 'main', 'contribution', 'of', 'this', 'paper', 'is', 'the', 'development', 'of', 'a', 'scheduling', 'algorithm', 'multi-objective', 'optimization', 'with', 'nar-nn', 'to', 'minimize', 'the', 'electricity', 'bill', 'and', 'customer', '’', 's', 'discomfort', 'considering', 'the', 'operational', 'dynamic', 'of', 'non-schedulable', 'load', 'and', 'electricity', 'price', 'variation', 'to', 'avoid', 'consumer', \"'s\", 'discomfort', 'a', 'scheduling', 'algorithm', 'is', 'applied', 'using', 'historical', 'data', 'of', 'the', 'consumer', \"'s\", 'habit', 'and', 'pv', 'generation', 'forecast']\n",
      "II.  PROBLEM STATEMENT  \n",
      "['ii', 'problem', 'statement']\n",
      "The residential demand management problem is a non- \n",
      "['the', 'residential', 'demand', 'management', 'problem', 'is', 'a', 'non-']\n",
      "linear programming problem aimed at minimizing power  consumption and customers discomfort subject to some  constraints.  \n",
      "['linear', 'programming', 'problem', 'aimed', 'at', 'minimizing', 'power', 'consumption', 'and', 'customer', 'discomfort', 'subject', 'to', 'some', 'constraint']\n",
      "A. Power Consumption Minimization  \n",
      "['a', 'power', 'consumption', 'minimization']\n",
      "   Residential loads based on the power consumption  \n",
      "['residential', 'load', 'based', 'on', 'the', 'power', 'consumption']\n",
      "pattern   are categorized into two types:   \n",
      "['pattern', 'are', 'categorized', 'into', 'two', 'type']\n",
      "• Fixed loads: whose power consumption and usage time  \n",
      "['•', 'fixed', 'load', 'whose', 'power', 'consumption', 'and', 'usage', 'time']\n",
      "cannot be modified (e.g., TV, refrigerator). It is assumed  that the algorithm does not have any control on these loads.   \n",
      "['can', 'not', 'be', 'modified', 'eg', 'tv', 'refrigerator', 'it', 'is', 'assumed', 'that', 'the', 'algorithm', 'doe', 'not', 'have', 'any', 'control', 'on', 'these', 'load']\n",
      "• Shiftable loads: whose power consumption can be shifted  \n",
      "['•', 'shiftable', 'load', 'whose', 'power', 'consumption', 'can', 'be', 'shifted']\n",
      "to a different source or time slot to operate on its own power  consumption pattern (e.g. air conditioner, washing  machine, and dishwasher).  \n",
      "['to', 'a', 'different', 'source', 'or', 'time', 'slot', 'to', 'operate', 'on', 'it', 'own', 'power', 'consumption', 'pattern', 'eg', 'air', 'conditioner', 'washing', 'machine', 'and', 'dishwasher']\n",
      "The goal is to schedules the consumption of each shiftable  \n",
      "['the', 'goal', 'is', 'to', 'schedule', 'the', 'consumption', 'of', 'each', 'shiftable']\n",
      "device to minimize the difference between the load  consumption curve and the objective curve. Load shifting for  power consumption minimization can be mathematically  formulated as follows:  \n",
      "['device', 'to', 'minimize', 'the', 'difference', 'between', 'the', 'load', 'consumption', 'curve', 'and', 'the', 'objective', 'curve', 'load', 'shifting', 'for', 'power', 'consumption', 'minimization', 'can', 'be', 'mathematically', 'formulated', 'a', 'follows']\n",
      "𝑀𝑖𝑛𝑖𝑚𝑖𝑧𝑒    𝐽(t, p) = |𝑃𝐶 \n",
      "['𝑀𝑖𝑛𝑖𝑚𝑖𝑧𝑒', '𝐽t', 'p', '=', '|𝑃𝐶']\n",
      "𝑡 − 𝑃𝑂 \n",
      "['𝑡', '−', '𝑃𝑂']\n",
      "𝑡|2 (1)  \n",
      "['𝑡|_digit_digit_\\uf020', '_digit_digit_']\n",
      "B. Discomfort minimization         One of the main advantages of the proposed algorithm is  to model load demand patterns based on the customers’  lifestyle so that their discomfort can be minimized. The  following minimization problem considering different  weights (𝑤𝑠, 𝑘𝑠) is defined to minimize the customer  discomfort:  \n",
      "['b', 'discomfort', 'minimization', 'one', 'of', 'the', 'main', 'advantage', 'of', 'the', 'proposed', 'algorithm', 'is', 'to', 'model', 'load', 'demand', 'pattern', 'based', 'on', 'the', 'customer', '’', 'lifestyle', 'so', 'that', 'their', 'discomfort', 'can', 'be', 'minimized', 'the', 'following', 'minimization', 'problem', 'considering', 'different', 'weight', '𝑤𝑠', '𝑘𝑠', 'is', 'defined', 'to', 'minimize', 'the', 'customer', 'discomfort']\n",
      "𝑀𝑖𝑛𝑖𝑚𝑖𝑧𝑒 ∑ 𝑤𝑠𝑑𝑠 + 𝑘𝑠𝐷𝑠 \n",
      "['𝑀𝑖𝑛𝑖𝑚𝑖𝑧𝑒', '∑', '𝑤𝑠𝑑𝑠', '+', '𝑘𝑠𝐷𝑠']\n",
      "𝑠∈𝑆 \n",
      "['𝑠∈𝑆']\n",
      "  (2)  \n",
      "['_digit_digit_']\n",
      "C. Constraint          The minimization problem is subject to the following  constraints:  \n",
      "['c', 'constraint', 'the', 'minimization', 'problem', 'is', 'subject', 'to', 'the', 'following', 'constraint']\n",
      "1. The number of devices shifted cannot be a negative value.  \n",
      "['_digit_digit_', 'the', 'number', 'of', 'device', 'shifted', 'can', 'not', 'be', 'a', 'negative', 'value']\n",
      "𝑡, 𝑓𝑗 \n",
      "['𝑡', '𝑓𝑗']\n",
      "𝑡, 𝑠𝑘 \n",
      "['𝑡', '𝑠𝑘']\n",
      "𝑡 > 0  ∀ 𝑖, 𝑗, 𝑘  (3)  \n",
      "['𝑡', '_digit_digit_', '∀', '𝑖', '𝑗', '𝑘', '_digit_digit_']\n",
      "2. The number of shiftable devices cannot be more than the  \n",
      "['_digit_digit_', 'the', 'number', 'of', 'shiftable', 'device', 'can', 'not', 'be', 'more', 'than', 'the']\n",
      "number of devices available for control at each time step.  \n",
      "['number', 'of', 'device', 'available', 'for', 'control', 'at', 'each', 'time', 'step']\n",
      "∑ 𝑠𝑘 \n",
      "['∑', '𝑠𝑘']\n",
      "𝑘=1 \n",
      "['𝑘=_digit_digit_']\n",
      "≤ 𝐷𝑐  \n",
      "['≤', '𝐷𝑐']\n",
      "  (4)  \n",
      "['_digit_digit_']\n",
      "3. Each shiftable devices is allowed to work in a specific time  \n",
      "['_digit_digit_', 'each', 'shiftable', 'device', 'is', 'allowed', 'to', 'work', 'in', 'a', 'specific', 'time']\n",
      "slot.  \n",
      "['slot']\n",
      "∑ 𝑥𝑛𝑠 \n",
      "['∑', '𝑥𝑛𝑠']\n",
      "𝑇𝐴𝑝𝑝 \n",
      "['𝑇𝐴𝑝𝑝']\n",
      "𝐸𝑛𝑠−𝑇𝐴𝑝𝑝+1 \n",
      "['𝐸𝑛𝑠−𝑇𝐴𝑝𝑝+_digit_digit_']\n",
      "𝑛=𝑇𝐴𝑝𝑝 \n",
      "['𝑛=𝑇𝐴𝑝𝑝']\n",
      "𝑆𝑡𝑎𝑟𝑡 \n",
      "['𝑆𝑡𝑎𝑟𝑡']\n",
      "= 1      ∀   𝑠 ∈ 𝑆  \n",
      "['=', '_digit_digit_', '∀', '𝑠', '∈', '𝑆']\n",
      "  (5)  \n",
      "['_digit_digit_']\n",
      "III.  INCENTIVE-BASED DEMAND RESPONSE OPTIMIZATION  \n",
      "['iii', 'incentive-based', 'demand', 'response', 'optimization']\n",
      "(IDRO)  \n",
      "['idro']\n",
      "The proposed IDRO algorithm provides an opportunity to  \n",
      "['the', 'proposed', 'idro', 'algorithm', 'provides', 'an', 'opportunity', 'to']\n",
      "the consumers to voluntarily participate in the DRM. This  algorithm considers the combined sources of energy provided  by the grid and rooftop installed PV to implement DRM. As it  was mentioned in previous section, loads are divided into fixed  and shiftable ones. Each load can determine their permitted  time used for shifting as the input of the algorithm. According  to the schedules provided by the consumers, IDRO can decide  whether their consumption is supplied through the grid or PV.  This algorithm has several steps which are explained in this  section.  \n",
      "['the', 'consumer', 'to', 'voluntarily', 'participate', 'in', 'the', 'drm', 'this', 'algorithm', 'considers', 'the', 'combined', 'source', 'of', 'energy', 'provided', 'by', 'the', 'grid', 'and', 'rooftop', 'installed', 'pv', 'to', 'implement', 'drm', 'a', 'it', 'wa', 'mentioned', 'in', 'previous', 'section', 'load', 'are', 'divided', 'into', 'fixed', 'and', 'shiftable', 'one', 'each', 'load', 'can', 'determine', 'their', 'permitted', 'time', 'used', 'for', 'shifting', 'a', 'the', 'input', 'of', 'the', 'algorithm', 'according', 'to', 'the', 'schedule', 'provided', 'by', 'the', 'consumer', 'idro', 'can', 'decide', 'whether', 'their', 'consumption', 'is', 'supplied', 'through', 'the', 'grid', 'or', 'pv', 'this', 'algorithm', 'ha', 'several', 'step', 'which', 'are', 'explained', 'in', 'this', 'section']\n",
      "A. Methodology   \n",
      "['a', 'methodology']\n",
      "Artificial neural network (ANN) is a well-known data  \n",
      "['artificial', 'neural', 'network', 'ann', 'is', 'a', 'well-known', 'data']\n",
      "processing algorithm to model non-linear systems. It works  efficiently particularly when there are complex non-linear  relationships between system input and output.  \n",
      "['processing', 'algorithm', 'to', 'model', 'non-linear', 'system', 'it', 'work', 'efficiently', 'particularly', 'when', 'there', 'are', 'complex', 'non-linear', 'relationship', 'between', 'system', 'input', 'and', 'output']\n",
      " In this paper, a feed-forward neural network with  \n",
      "['in', 'this', 'paper', 'a', 'feed-forward', 'neural', 'network', 'with']\n",
      "Levenberg–Marquardt (LM) training algorithm is chosen for  training the Nonlinear Auto-Regressive Neural Network  (NAR-NN). According to the Fig. 1, the total consumption  pattern for each hour of day during different months  significantly varies.  \n",
      "['levenberg–marquardt', 'lm', 'training', 'algorithm', 'is', 'chosen', 'for', 'training', 'the', 'nonlinear', 'auto-regressive', 'neural', 'network', 'nar-nn', 'according', 'to', 'the', 'fig', '_digit_digit_', 'the', 'total', 'consumption', 'pattern', 'for', 'each', 'hour', 'of', 'day', 'during', 'different', 'month', 'significantly', 'varies']\n",
      "<image: DeviceRGB, width: 680, height: 215, bpc: 8>\n",
      "['_image_']\n",
      "Fig. 1. Example of load consumption during different months of a year.  \n",
      "['fig', '_digit_digit_', 'example', 'of', 'load', 'consumption', 'during', 'different', 'month', 'of', 'a', 'year']\n",
      "Therefore, in this network, different weight is assigned to  \n",
      "['therefore', 'in', 'this', 'network', 'different', 'weight', 'is', 'assigned', 'to']\n",
      "historical data during a specific month/week of the year for  each appliance. Historical data (network input) are used to  predict the load consumption ahead of the time (network  output). A hidden is a layer in between the input layers and  output layers, where neurons receive a set of weighted inputs  and generate an output using an activation function. The neural  network architecture used in this work is given in Figure 2.  \n",
      "['historical', 'data', 'during', 'a', 'specific', 'month/week', 'of', 'the', 'year', 'for', 'each', 'appliance', 'historical', 'data', 'network', 'input', 'are', 'used', 'to', 'predict', 'the', 'load', 'consumption', 'ahead', 'of', 'the', 'time', 'network', 'output', 'a', 'hidden', 'is', 'a', 'layer', 'in', 'between', 'the', 'input', 'layer', 'and', 'output', 'layer', 'where', 'neuron', 'receive', 'a', 'set', 'of', 'weighted', 'input', 'and', 'generate', 'an', 'output', 'using', 'an', 'activation', 'function', 'the', 'neural', 'network', 'architecture', 'used', 'in', 'this', 'work', 'is', 'given', 'in', 'figure', '_digit_digit_']\n",
      "<image: DeviceRGB, width: 660, height: 200, bpc: 8>\n",
      "['_image_']\n",
      "Fig. 2. NAR-NN basic scheme  \n",
      "['fig', '_digit_digit_', 'nar-nn', 'basic', 'scheme']\n",
      "The relationship between input and output of NA-RNN can  \n",
      "['the', 'relationship', 'between', 'input', 'and', 'output', 'of', 'na-rnn', 'can']\n",
      "be written as:  \n",
      "['be', 'written', 'a']\n",
      "𝑉 (𝑡) = ℎ(𝑉(𝑡 − 1),  𝑉(𝑡 − 2),  … ,  𝑉(𝑡 − 𝑡𝑑)) + 𝑒(𝑡)    (6)  \n",
      "['𝑉', '𝑡', '=', 'ℎ𝑉𝑡', '−', '_digit_digit_', '𝑉𝑡', '−', '_digit_digit_', '…', '𝑉𝑡', '−', '𝑡𝑑', '+', '𝑒𝑡', '_digit_digit_']\n"
     ]
    }
   ],
   "source": [
    "for i in range(99):\n",
    "    print_version(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4339861"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['smart', 'household', 'demand', 'response', 'management'],\n",
       " ['with', 'micro', 'grid'],\n",
       " ['hossein',\n",
       "  'mohammadi',\n",
       "  'ruzbahani',\n",
       "  'abolfazl',\n",
       "  'rahimnejad',\n",
       "  'hadis',\n",
       "  'karimipour'],\n",
       " ['school', 'of', 'engineering', 'university', 'of', 'guelph'],\n",
       " ['guelph', 'canada'],\n",
       " ['{', 'hkarimi', 'hmoham_digit_digit_', 'arahimne', '}', '@', 'uoguelphca'],\n",
       " ['abstract',\n",
       "  'nowadays',\n",
       "  'the',\n",
       "  'emerging',\n",
       "  'smart',\n",
       "  'grid',\n",
       "  'technology',\n",
       "  'open',\n",
       "  'up',\n",
       "  'the',\n",
       "  'possibility',\n",
       "  'of',\n",
       "  'two-way',\n",
       "  'communication',\n",
       "  'between',\n",
       "  'customer',\n",
       "  'and',\n",
       "  'energy',\n",
       "  'utility',\n",
       "  'demand',\n",
       "  'response',\n",
       "  'management',\n",
       "  'drm',\n",
       "  'offer',\n",
       "  'the',\n",
       "  'promise',\n",
       "  'of',\n",
       "  'saving',\n",
       "  'money',\n",
       "  'for',\n",
       "  'commercial',\n",
       "  'customer',\n",
       "  'and',\n",
       "  'household',\n",
       "  'while',\n",
       "  'help',\n",
       "  'utility',\n",
       "  'operate',\n",
       "  'more',\n",
       "  'efficiently',\n",
       "  'in',\n",
       "  'this',\n",
       "  'paper',\n",
       "  'an',\n",
       "  'incentive-based',\n",
       "  'demand',\n",
       "  'response',\n",
       "  'optimization',\n",
       "  'idro',\n",
       "  'model',\n",
       "  'is',\n",
       "  'proposed',\n",
       "  'to',\n",
       "  'efficiently',\n",
       "  'schedule',\n",
       "  'household',\n",
       "  'appliance',\n",
       "  'for',\n",
       "  'minimum',\n",
       "  'usage',\n",
       "  'during',\n",
       "  'peak',\n",
       "  'hour',\n",
       "  'the',\n",
       "  'proposed',\n",
       "  'method',\n",
       "  'is',\n",
       "  'a',\n",
       "  'multi-objective',\n",
       "  'optimization',\n",
       "  'technique',\n",
       "  'based',\n",
       "  'on',\n",
       "  'nonlinear',\n",
       "  'auto-regressive',\n",
       "  'neural',\n",
       "  'network',\n",
       "  'nar-nn',\n",
       "  'which',\n",
       "  'considers',\n",
       "  'energy',\n",
       "  'provided',\n",
       "  'by',\n",
       "  'the',\n",
       "  'utility',\n",
       "  'and',\n",
       "  'rooftop',\n",
       "  'installed',\n",
       "  'photovoltaic',\n",
       "  'pv',\n",
       "  'system',\n",
       "  'the',\n",
       "  'proposed',\n",
       "  'method',\n",
       "  'is',\n",
       "  'tested',\n",
       "  'and',\n",
       "  'verified',\n",
       "  'using',\n",
       "  '_digit_digit_',\n",
       "  'case',\n",
       "  'study',\n",
       "  'household',\n",
       "  'data',\n",
       "  'analysis',\n",
       "  'for',\n",
       "  'a',\n",
       "  'period',\n",
       "  'of',\n",
       "  'one',\n",
       "  'year',\n",
       "  'show',\n",
       "  'a',\n",
       "  'noticeable',\n",
       "  'improvement',\n",
       "  'in',\n",
       "  'power',\n",
       "  'factor',\n",
       "  'and',\n",
       "  'customer',\n",
       "  '’',\n",
       "  'bill'],\n",
       " ['keywords',\n",
       "  'demand',\n",
       "  'response',\n",
       "  'management',\n",
       "  'optimization',\n",
       "  'peak',\n",
       "  'hour',\n",
       "  'smart',\n",
       "  'home',\n",
       "  'smart',\n",
       "  'grid'],\n",
       " ['nomenclature'],\n",
       " ['𝑚',\n",
       "  'total',\n",
       "  'number',\n",
       "  'of',\n",
       "  'uninterruptible',\n",
       "  'load',\n",
       "  '𝐻',\n",
       "  'time',\n",
       "  'slot',\n",
       "  '_digit_digit_',\n",
       "  'minute',\n",
       "  '𝑃𝐶']]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_token[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sent_path_=\"~/drive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_token_list=[str(data_token_i) for data_token_i in data_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g',\n",
       " 'added',\n",
       " 'to',\n",
       " 'the',\n",
       " 'clique',\n",
       " 'number',\n",
       " 'of',\n",
       " 'g',\n",
       " 'equal',\n",
       " 'the',\n",
       " 'size',\n",
       " 'of',\n",
       " 'g',\n",
       " 'ﬁnding',\n",
       " 'an',\n",
       " 'approximation',\n",
       " 'of',\n",
       " 'the']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_token[1353]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(fname:str,dlist:list):\n",
    "    f=open(fname,\"w\",encoding=\"utf-8\")\n",
    "    for element in dlist:\n",
    "        f.write(str(element)+\"\\n\")\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list(fname:str):\n",
    "    f=open(fname,\"r\", encoding=\"utf-8\")\n",
    "    for i in range(10):\n",
    "        line=f.readline()\n",
    "        print(line)\n",
    "    f.close()\n",
    "    print(\"End\")\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python read text file\n"
     ]
    }
   ],
   "source": [
    "print(\"python read text file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_corpus(textlist,meta):\n",
    "    index_list=[]\n",
    "    ol=textlist[:]\n",
    "    om=meta[:]\n",
    "    # a tisztítandó elemek összegyűjtése\n",
    "    print(\"selection\", end='')\n",
    "\n",
    "    for text_index,text in enumerate(textlist):\n",
    "        if len (text)==0:\n",
    "            index_list.append(text_index)\n",
    "\n",
    "        elif text[0]==\"_image_\" :\n",
    "            index_list.append(text_index)\n",
    "        if text_index % 10000==0:\n",
    "            print(text_index,end=\"-\")\n",
    "    # remove \n",
    "    print(f\"removing {len(index_list)} db.\")\n",
    "    i=0\n",
    "    index_list.sort(reverse=True)\n",
    "    for text_index in index_list:\n",
    "        ol.pop(text_index)\n",
    "        om.pop(text_index)\n",
    "        i+=1\n",
    "\n",
    "        if i % 10000==0:\n",
    "            print(text_index,end=\"-\")\n",
    "     \n",
    "    return ol,om\n",
    "\n",
    "def reindex_meta(meta):\n",
    "    for meta_index, _ in enumerate(meta):\n",
    "        meta[meta_index][\"_id\"]=meta_index \n",
    "        meta[meta_index][\"index\"]=meta_index\n",
    "    return meta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selection0-10000-20000-30000-40000-50000-60000-70000-80000-90000-100000-110000-120000-130000-140000-150000-160000-170000-180000-190000-200000-210000-220000-230000-240000-250000-260000-270000-280000-290000-300000-310000-320000-330000-340000-350000-360000-370000-380000-390000-400000-410000-420000-430000-440000-450000-460000-470000-480000-490000-500000-510000-520000-530000-540000-550000-560000-570000-580000-590000-600000-610000-620000-630000-640000-650000-660000-670000-680000-690000-700000-710000-720000-730000-740000-750000-760000-770000-780000-790000-800000-810000-820000-830000-840000-850000-860000-870000-880000-890000-900000-910000-920000-930000-940000-950000-960000-970000-980000-990000-1000000-1010000-1020000-1030000-1040000-1050000-1060000-1070000-1080000-1090000-1100000-1110000-1120000-1130000-1140000-1150000-1160000-1170000-1180000-1190000-1200000-1210000-1220000-1230000-1240000-1250000-1260000-1270000-1280000-1290000-1300000-1310000-1320000-1330000-1340000-1350000-1360000-1370000-1380000-1390000-1400000-1410000-1420000-1430000-1440000-1450000-1460000-1470000-1480000-1490000-1500000-1510000-1520000-1530000-1540000-1550000-1560000-1570000-1580000-1590000-1600000-1610000-1620000-1630000-1640000-1650000-1660000-1670000-1680000-1690000-1700000-1710000-1720000-1730000-1740000-1750000-1760000-1770000-1780000-1790000-1800000-1810000-1820000-1830000-1840000-1850000-1860000-1870000-1880000-1890000-1900000-1910000-1920000-1930000-1940000-1950000-1960000-1970000-1980000-1990000-2000000-2010000-2020000-2030000-2040000-2050000-2060000-2070000-2080000-2090000-2100000-2110000-2120000-2130000-2140000-2150000-2160000-2170000-2180000-2190000-2200000-2210000-2220000-2230000-2240000-2250000-2260000-2270000-2280000-2290000-2300000-2310000-2320000-2330000-2340000-2350000-2360000-2370000-2380000-2390000-2400000-2410000-2420000-2430000-2440000-2450000-2460000-2470000-2480000-2490000-2500000-2510000-2520000-2530000-2540000-2550000-2560000-2570000-2580000-2590000-2600000-2610000-2620000-2630000-2640000-2650000-2660000-2670000-2680000-2690000-2700000-2710000-2720000-2730000-2740000-2750000-2760000-2770000-2780000-2790000-2800000-2810000-2820000-2830000-2840000-2850000-2860000-2870000-2880000-2890000-2900000-2910000-2920000-2930000-2940000-2950000-2960000-2970000-2980000-2990000-3000000-3010000-3020000-3030000-3040000-3050000-3060000-3070000-3080000-3090000-3100000-3110000-3120000-3130000-3140000-3150000-3160000-3170000-3180000-3190000-3200000-3210000-3220000-3230000-3240000-3250000-3260000-3270000-3280000-3290000-3300000-3310000-3320000-3330000-3340000-3350000-3360000-3370000-3380000-3390000-3400000-3410000-3420000-3430000-3440000-3450000-3460000-3470000-3480000-3490000-3500000-3510000-3520000-3530000-3540000-3550000-3560000-3570000-3580000-3590000-3600000-3610000-3620000-3630000-3640000-3650000-3660000-3670000-3680000-3690000-3700000-3710000-3720000-3730000-3740000-3750000-3760000-3770000-3780000-3790000-3800000-3810000-3820000-3830000-3840000-3850000-3860000-3870000-3880000-3890000-3900000-3910000-3920000-3930000-3940000-3950000-3960000-3970000-3980000-3990000-4000000-4010000-4020000-4030000-4040000-4050000-4060000-4070000-4080000-4090000-4100000-4110000-4120000-4130000-4140000-4150000-4160000-4170000-4180000-4190000-4200000-4210000-4220000-4230000-4240000-4250000-4260000-4270000-4280000-4290000-4300000-4310000-4320000-4330000-removing 626311 db.\n",
      "4273097-4184267-4117668-4055091-3990518-3923449-3876870-3801705-3733735-3648327-3578579-3532475-3448005-3368983-3317028-3248266-3144911-3061322-2975811-2905689-2840022-2760574-2699441-2606606-2542403-2481932-2424347-2357780-2233254-2197581-2156928-2059144-1999614-1892216-1852963-1842954-1832922-1822896-1784525-1693624-1617432-1561292-1486043-1415402-1326614-1262102-1176936-1098281-1026902-963888-902658-828613-768742-703835-602665-536587-465275-402226-344046-254230-172706-74177-"
     ]
    }
   ],
   "source": [
    "d1,m1=optimize_corpus(data_token,meta_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2=reindex_meta(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 99,\n",
       " 'index': 99,\n",
       " 'fname': '1907.03641',\n",
       " 'page': 2,\n",
       " 'pos0': 65,\n",
       " 'pos1': 122,\n",
       " 'pos2': 299,\n",
       " 'pos3': 133}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list(_corpus_+_corpus_name_,d1[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta=pd.DataFrame(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>index</th>\n",
       "      <th>fname</th>\n",
       "      <th>page</th>\n",
       "      <th>pos0</th>\n",
       "      <th>pos1</th>\n",
       "      <th>pos2</th>\n",
       "      <th>pos3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3713545</th>\n",
       "      <td>3713545</td>\n",
       "      <td>3713545</td>\n",
       "      <td>2203.09517</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>374</td>\n",
       "      <td>369</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713546</th>\n",
       "      <td>3713546</td>\n",
       "      <td>3713546</td>\n",
       "      <td>2203.09517</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>408</td>\n",
       "      <td>379</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713547</th>\n",
       "      <td>3713547</td>\n",
       "      <td>3713547</td>\n",
       "      <td>2203.09517</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>153</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713548</th>\n",
       "      <td>3713548</td>\n",
       "      <td>3713548</td>\n",
       "      <td>2203.09517</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>545</td>\n",
       "      <td>343</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713549</th>\n",
       "      <td>3713549</td>\n",
       "      <td>3713549</td>\n",
       "      <td>2203.09517</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>567</td>\n",
       "      <td>381</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             _id    index       fname  page  pos0  pos1  pos2  pos3\n",
       "3713545  3713545  3713545  2203.09517    28    40   374   369   405\n",
       "3713546  3713546  3713546  2203.09517    28    33   408   379   429\n",
       "3713547  3713547  3713547  2203.09517    29    34    11   153    20\n",
       "3713548  3713548  3713548  2203.09517    29    54   545   343   554\n",
       "3713549  3713549  3713549  2203.09517    29    34   567   381   589"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arXiv_sentences_20220318_133000.txt'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_corpus_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.to_csv(_corpus_+\"_META_\"+_corpus_name_,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname, counter=0):\n",
    "    out=[]\n",
    "    f=open(fname,\"r\",encoding=\"UTF-8\")\n",
    "    if counter!=0:\n",
    "        for i in range(counter):\n",
    "            one_line=f.readline()\n",
    "            out.append(one_line.strip())\n",
    "    else:\n",
    "        while True:\n",
    "            one_line=f.readline()\n",
    "            if one_line==\"\":\n",
    "                print(\"EOF\")\n",
    "                \n",
    "                break\n",
    "            out.append(one_line.strip())\n",
    "\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOF\n"
     ]
    }
   ],
   "source": [
    "corpus_lst=read_file(_corpus_+_corpus_name_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3713550"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['while', 'daily', 'low', 'and', 'high', 'lh', 'price', 'signiﬁcantly', 'increase', 'the', 'amount', 'of', 'information', 'about', 'the', 'variation']\",\n",
       " \"['of', 'return', 'during', 'a', 'day', 'lh', 'price', 'were', 'used', 'for', 'the', 'construction', 'of', 'highly', 'eﬃcient', 'estimator', 'of', 'vari-']\",\n",
       " \"['ance', 'so', 'called', 'the', 'range-based', 'rb', 'estimator', 'eg', 'parkinson', '_digit_digit_', ';', 'garman', 'and', 'klass', '_digit_digit_', ';', 'rogers']\",\n",
       " \"['and', 'satchell', '_digit_digit_', ';', 'yang', 'and', 'zhang', '_digit_digit_', ';', 'magdon-ismail', 'and', 'atiya', '_digit_digit_', ';', 'fiszeder', 'and', 'perczak', '_digit_digit_']\",\n",
       " \"['recently', 'riedel', '_digit_digit_', 'analysed', 'how', 'much', 'additional', 'information', 'about', 'lh', 'reduces', 'the', 'time', 'averaged']\",\n",
       " \"['variance', 'in', 'comparison', 'to', 'knowing', 'only', 'open', 'and', 'close', 'rb', 'variance', 'estimator', 'however', 'have', 'a', 'funda-']\",\n",
       " \"['mental', 'drawback', 'a', 'they', 'neglect', 'the', 'temporal', 'dependence', 'of', 'return', 'like', 'conditional', 'heteroscedasticity']\",\n",
       " \"['and', 'do', 'not', 'allow', 'for', 'the', 'calculation', 'of', 'multi-period', 'dynamic', 'volatility', 'forecast']\",\n",
       " \"['_digit_digit_this', 'subsection', 'wa', 'written', 'by', 'piotr', 'fiszeder']\",\n",
       " \"['in', 'the', 'last', 'dozen', 'or', 'so', 'year', 'numerous', 'univariate', 'dynamic', 'volatility', 'model', 'have', 'been', 'constructed']\",\n",
       " \"['based', 'on', 'lh', 'price', 'some', 'of', 'them', 'were', 'presented', 'in', 'the', 'review', 'paper', 'of', 'chou', 'et', 'al', '_digit_digit_', 'these', 'model']\",\n",
       " \"['can', 'be', 'divided', 'into', 'four', 'group', 'the', 'ﬁrst', 'one', 'comprises', 'simple', 'model', 'used', 'traditionally', 'to', 'describe']\",\n",
       " \"['return', 'but', 'they', 'are', 'based', 'on', 'the', 'price', 'range', 'or', 'on', 'the', 'mentioned', 'earlier', 'rb', 'variance', 'estimator', 'they']\",\n",
       " \"['include', 'such', 'model', 'a', 'random', 'walk', 'moving', 'average', 'exponentially', 'weighted', 'moving', 'average', 'ewma']\",\n",
       " \"['autoregressive', 'ar', 'autoregressive', 'moving', 'average', 'arma', ';', 'see', '§_digit_digit_', 'and', 'heterogeneous', 'autoregressive', 'har', 'the', 'second', 'group', 'contains', 'model', 'which', 'describe', 'the', 'conditional', 'variance', 'or', 'standard', 'devia-']\",\n",
       " \"['tion', 'of', 'return', 'it', 'comprises', 'model', 'like', 'garch-park-r', 'mapa', '_digit_digit_', 'garch-tr', 'fiszeder', '_digit_digit_']\",\n",
       " \"['regarch', 'brandt', 'and', 'jones', '_digit_digit_', 'rgarch', 'moln´ar', '_digit_digit_', 'the', 'third', 'group', 'includes', 'model', 'which']\",\n",
       " \"['describe', 'the', 'conditional', 'mean', 'of', 'the', 'price', 'range', 'it', 'mean', 'that', 'in', 'order', 'to', 'forecast', 'variance', 'of', 'return', 'the']\",\n",
       " \"['result', 'have', 'to', 'be', 'scaled', 'this', 'group', 'contains', 'model', 'like', 'rb', 'sv', 'alizadeh', 'et', 'al', '_digit_digit_', 'carr', 'chou']\",\n",
       " \"['_digit_digit_', 'tarr', 'chen', 'et', 'al', '_digit_digit_', 'cargpr', 'chan', 'et', 'al', '_digit_digit_', 'starr', 'lin', 'et', 'al', '_digit_digit_', 'and', 'msrb', 'miao']\",\n",
       " \"['et', 'al', '_digit_digit_', 'the', 'last', 'group', 'is', 'methodologically', 'diﬀerent', 'because', 'the', 'estimation', 'of', 'model', 'parameter', 'is']\",\n",
       " \"['based', 'on', 'the', 'set', 'of', 'three', 'price', 'ie', 'low', 'high', 'and', 'closing', 'this', 'approach', 'comprises', 'the', 'garch', 'model']\",\n",
       " \"['lildholdt', '_digit_digit_', ';', 'venter', 'et', 'al', '_digit_digit_', ';', 'fiszeder', 'and', 'perczak', '_digit_digit_', 'and', 'the', 'sv', 'model', 'horst', 'et', 'al', '_digit_digit_']\",\n",
       " \"['the', 'development', 'of', 'multivariate', 'model', 'with', 'lh', 'price', 'ha', 'taken', 'place', 'in', 'the', 'last', 'few', 'year', 'they']\",\n",
       " \"['can', 'be', 'divided', 'into', 'three', 'group', 'the', 'ﬁrst', 'one', 'includes', 'model', 'used', 'traditionally', 'to', 'describe', 'return']\",\n",
       " \"['or', 'price', 'but', 'they', 'are', 'based', 'on', 'the', 'price', 'range', 'or', 'rb', 'variance', 'estimator', 'they', 'comprise', 'such', 'model']\",\n",
       " \"['like', 'multivariate', 'ewma', 'var', 'hvar', 'and', 'vector', 'error', 'correction', 'vec', 'it', 'is', 'a', 'simple', 'approach', 'however']\",\n",
       " \"['most', 'model', 'omit', 'modelling', 'the', 'covariance', 'of', 'return', 'the', 'second', 'group', 'is', 'formed', 'by', 'the', 'multivariate']\",\n",
       " \"['rb', 'volatility', 'model', 'like', 'rb-dcc', 'chou', 'et', 'al', '_digit_digit_', 'dstcc-carr', 'chou', 'and', 'cai', '_digit_digit_', 'rr-hgadcc']\",\n",
       " \"['asai', '_digit_digit_', 'rb-ms-dcc', 'su', 'and', 'wu', '_digit_digit_', 'dcc-rgarch', 'fiszeder', 'et', 'al', '_digit_digit_', 'rb-copula', 'chiang']\",\n",
       " \"['and', 'wang', '_digit_digit_', ';', 'wu', 'and', 'liang', '_digit_digit_', 'the', 'third', 'group', 'includes', 'the', 'multivariate', 'co-range', 'volatility', 'mod-']\",\n",
       " \"['el', 'like', 'multivariate', 'carr', 'fernandes', 'et', 'al', '_digit_digit_', 'bekk-hl', 'fiszeder', '_digit_digit_', 'and', 'co-range', 'dcc', 'fiszeder']\",\n",
       " \"['and', 'fałdzi´nski', '_digit_digit_', 'these', 'model', 'apply', 'lh', 'price', 'directly', 'not', 'only', 'for', 'the', 'construction', 'of', 'variance', 'of']\",\n",
       " \"['return', 'but', 'also', 'for', 'covariance', '§_digit_digit_', 'discus', 'the', 'use', 'of', 'the', 'range-based', 'volatility', 'model', 'in', 'ﬁnancial']\",\n",
       " \"['time', 'series', 'forecasting']\",\n",
       " \"['_digit_digit_', 'forecasting', 'with', 'dsge', 'models_digit_digit_']\",\n",
       " \"['dynamic', 'stochastic', 'general', 'equilibrium', 'dsge', 'model', 'are', 'the', 'workhorse', 'of', 'modern', 'macroeconomics']\",\n",
       " \"['employed', 'by', 'monetary', 'and', 'ﬁscal', 'authority', 'to', 'explain', 'and', 'forecast', 'comovements', 'of', 'aggregate', 'time', 'se-']\",\n",
       " \"['ries', 'over', 'the', 'business', 'cycle', 'and', 'to', 'perform', 'quantitative', 'policy', 'analysis', 'these', 'model', 'are', 'studied', 'in', 'both']\",\n",
       " \"['academia', 'and', 'policy-making', 'institution', 'for', 'detail', 'see', 'del', 'negro', 'and', 'schorfheide', '_digit_digit_', ';', 'paccagnini']\",\n",
       " \"['_digit_digit_', ';', 'christiano', 'et', 'al', '_digit_digit_', 'for', 'example', 'the', 'european', 'central', 'bank', 'us', 'the', 'new', 'area-wide', 'model']\",\n",
       " \"['introduced', 'by', 'warne', 'et', 'al', '_digit_digit_', 'and', 'the', 'federal', 'reserve', 'board', 'ha', 'created', 'the', 'estimated', 'dynamic']\",\n",
       " \"['optimisation-based', 'model', 'frb/edo', 'a', 'discussed', 'in', 'chung', 'et', 'al', '_digit_digit_', 'for', 'an', 'application', 'on', 'forecasting', 'gdp', 'and', 'inﬂation', 'see', '§_digit_digit_', 'developed', 'a', 'a', 'response', 'to', 'lucas', '_digit_digit_', 'critique', 'of', 'structural', 'macroe-']\",\n",
       " \"['conometrics', 'model', 'dsges', 'introduced', 'microfundations', 'to', 'describe', 'business', 'cycle', 'ﬂuctuations', 'initially']\",\n",
       " \"['calibrated', 'estimated', 'dsges', 'have', 'been', 'employed', 'in', 'shock', 'identiﬁcation', 'and', 'forecasting', 'horseraces', 'for']\"]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lst[3000:3045]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—  CASE STUDY  Canada’s Wapiti Gas Plant gets head-start  with ABB’s Select I/O platform '"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_24[1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
